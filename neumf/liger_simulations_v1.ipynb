{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKYKzIk0coAS"
      },
      "source": [
        "## (A) Neural Matrix Factorizarion Steps -  NeuMF Paper\n",
        "\n",
        "1.   Usually given an \"object 1 by object 2\" observation matrix M with explicit feedback data.\n",
        "\n",
        "---\n",
        "\n",
        "2.   Two learning approaches can be adopted:\n",
        "\n",
        "*   Pointwise learning: follows a regression framework by minimizing the squred loss between *yPredicted* and *yObserved*.\n",
        "*   Pairwise learning: this ranks observed entries higher relative to unobserved entries, and maximizes the margin between them.\n",
        "\n",
        "---\n",
        "\n",
        "3. Electing pointwise learning, the training phase involves searching for the optimal parameters that minimizes this squared loss over a reduced (k-dimensional) feature space.\n",
        "\n",
        "---\n",
        "\n",
        "*   Predictions can then be made for the unobserved entries.\n",
        "*   In essence, both the observed and unobserved entries have been approximated by a non-linear function, which presumably improves upon linear(dot product) approximation.\n",
        "\n",
        "---\n",
        "\n",
        "What's often done(and adopted by the paper) is to restructure the problem to make use of implicit data (more easy to collect compared to explicit data)\n",
        "\n",
        "So in this case, the observation matrix M is converted into a binary interaction matrix P. The training prediction processes are similar as in the case of learning with M.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (B) Recovering the gene expression matrix(normalized) from LIGER ##\n",
        "\n",
        "1. Pass the downsampled control and interferon-stimulated PBMCs to the LIGER function.\n",
        "\n",
        "2. The LIGER function returns a normalized **H1, H2**, **V1, V2**, and **W**(shared) by performing non-negative matrix factorization.\n",
        "\n",
        "3. These matrices can be used to recover a dense representation of the original expression matrices.\n",
        "\n",
        "4. ** The \"cell paper\" then achieves integrative clustering by buildng a shared neighbourhood graph following the five steps of \"Joint clustering and factor normalization\" under the STAR methods.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (C) Self Implementation\n",
        "\n",
        "### Get data:\n",
        "1. A first option to getting the gene expression matrices is to recover them from the LIGER output.\n",
        "\n",
        "\n",
        "\n",
        "  *   The recovered matrices are a dense representation of the original expression matrices\n",
        "  *  Once the data is obtained this way, NeuMF cannot be applied for the simple reason that there are presumably no negative(unobserved/missing) instances.\n",
        "\n",
        "2. A second option will be to get the raw representation. This option will allow the application of NeuMF.\n",
        "\n",
        "---\n",
        "### Implementation Steps:\n",
        "\n",
        "1. Create a LIGER object with the raw data (stim & ctrl datasets)\n",
        "  -  This allows the recovery of a sparse gene by cell matrix.\n",
        "  - Cells not expressing any genes and genes not expressed in any cell are removed.\n",
        "  - Any remaining 0 is thus a \"true\" missing expression.\n",
        "  - Two sparse matrix representations will result; \"ctr_sparse\" and \"stim_sparse\"\n",
        "\n",
        "2. Feed the two sparse representations separately through the network.\n",
        "  - This will produce two dense representations of the sparse versions.\n",
        "  - The NeuMF will leverage any existing non-linear relationship between the cells and genes whiles maintaining the usual linear operations for better predictions.\n",
        "\n",
        "3. Using these two dense representations create a LIGER object with placeholders for H1, H2, V1, V2 and the shared matrix W.\n",
        "\n",
        "4. Scale and normalize the values of the resulting object. This ensures each gene has the same variance and also accounts for varying sequencing depths.\n",
        "\n",
        "5. Run the NMF algorithm from LIGER to get values for the matrices in (3)\n",
        "\n",
        "6. Build the shared neighbourhood graph and carry out the clustering. Implementation can be done with the LIGER package.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (D) Why this gives better clusters\n",
        "\n",
        "    ** will denote the paper implementation\n",
        "    *** will denote the corresponding implemntation in NeuMF\n",
        "---\n",
        "\n",
        "1. ### Factorization Method:\n",
        "\n",
        "---\n",
        "  ** -- Finds the matrices (of reduced dimensions) in (C)(3) by minimizing the penealized frobenius norm squared error between the observed and estimated matrices.\n",
        "\n",
        "  *** -- Finds some two lower dimensional matrics say U & V, that densely approximates the observed expression matrix by minimizing the MSE.\n",
        "\n",
        "  * The two loss functions are similar and differ only by a transformation.\n",
        "\n",
        "---\n",
        "\n",
        "2. ### Optimization Algorithm:\n",
        "\n",
        "---\n",
        "\n",
        "  **  -- Uses Block Cordinate Descent. It iteratively minimizes the factorization objective by making use of profiling. Convergence (local min) is guaranteed.\n",
        "\n",
        "  *** -- Uses Stochastic Gradient Descent. Simultaneously update model network parameters to minimze the loss function. Convergence is not guaranteed but saddle points in deep networks have shown to produce optimal functions than their shallow counterparts (BCD can be formulated as such).\n",
        "\n",
        "---\n",
        "\n",
        "3. ### Prediction Function:\n",
        "\n",
        "---\n",
        "\n",
        "  **  -- Basically a linear approximation.\n",
        "\n",
        "  *** -- Introduces non-linearities via the activation fucntions.\n",
        "\n",
        "---\n",
        "\n",
        "* For any cell gene expression matrix, NeuMF will always perform atleast as well as NMF Liger implementation. Performance will be indistninguishable if only linear (unlikely) relationship is present.\n",
        "\n",
        "* For the same factor specification k, performing Liger NMF on a dense output from NeuMF will not have any impact.\n",
        "\n",
        "* The above is why it makes sense to create a LIGER object with the matrices from NeuMF and cluster based on LIGERs NNB implementation.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKq2U_eCm4Vz"
      },
      "source": [
        "## **Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG9sxo1PcVRh",
        "outputId": "0d28dcf7-4bed-402c-de05-c5b563dd55bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# load packages\n",
        "import csv\n",
        "import math\n",
        "import time\n",
        "import umap\n",
        "import heapq\n",
        "!pip install hdbscan\n",
        "import hdbscan\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import urllib.request as urllib\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from sklearn.manifold import TSNE\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.utils import shuffle\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 3.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.29.18)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2308896 sha256=ccc5a956cd92c5bfad09cf4693e56f732f621b08883476ff42099b7c92aa7c18\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDREwBw_nVIz"
      },
      "source": [
        "## **(1) Load and Process Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4v8rZD_0v0"
      },
      "source": [
        "# load data\n",
        "url = 'https://sixtusdakurah.com/projects/liger/ctrl_sparse_dfp.csv'\n",
        "ctrl_sparse = pd.read_csv(url, sep=\",\", header=0)\n",
        "ctrl_sparse = ctrl_sparse.rename(columns={'Unnamed: 0': 'gene'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEa-s8V7j6KA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXU4LaYfBUvk",
        "outputId": "f67bbab1-d8fc-4a50-842b-c1d1abce1b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "# check dimensions and get brief view\n",
        "ctrl_sparse.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>ctrlTCAGCGCTGGTCAT-1</th>\n",
              "      <th>ctrlTTATGGCTTCATTC-1</th>\n",
              "      <th>ctrlACCCACTGCTTAGG-1</th>\n",
              "      <th>ctrlATGGGTACCCCGTT-1</th>\n",
              "      <th>ctrlTGACTGGACAGTCA-1</th>\n",
              "      <th>ctrlGTGTAGTGGTTGTG-1</th>\n",
              "      <th>ctrlTGCGAAACGCATCA-1</th>\n",
              "      <th>ctrlTTCAACACTGAGGG-1</th>\n",
              "      <th>ctrlATTACCACGAATGA-1</th>\n",
              "      <th>ctrlACGCCACTTCTTTG-1</th>\n",
              "      <th>ctrlTAAGATTGAGTCAC-1</th>\n",
              "      <th>ctrlGACGCCGATTACCT-1</th>\n",
              "      <th>ctrlCTGATTTGACTAGC-1</th>\n",
              "      <th>ctrlCTACTCCTTGAGAA-1</th>\n",
              "      <th>ctrlATGTCGGATCACCC-1</th>\n",
              "      <th>ctrlATGGACACTGGGAG-1</th>\n",
              "      <th>ctrlCTGACAGAACTACG-1</th>\n",
              "      <th>ctrlAACTTGCTGGTGGA-1</th>\n",
              "      <th>ctrlAACAGAGACGTTGA-1</th>\n",
              "      <th>ctrlCATCGGCTATGTGC-1</th>\n",
              "      <th>ctrlTCTCTAGAACTTTC-1</th>\n",
              "      <th>ctrlCCACCTGAATACCG-1</th>\n",
              "      <th>ctrlTACTACTGGGCGAA-1</th>\n",
              "      <th>ctrlGCACACCTCTGTCC-1</th>\n",
              "      <th>ctrlGCTCAGCTAAACAG-1</th>\n",
              "      <th>ctrlTGCATGGAACGGTT-1</th>\n",
              "      <th>ctrlAAGGCTACTCTATC-1</th>\n",
              "      <th>ctrlGAAAGCCTTCTTAC-1</th>\n",
              "      <th>ctrlCGTTTAACGCTTCC-1</th>\n",
              "      <th>ctrlTCGGCACTGGTATC-1</th>\n",
              "      <th>ctrlCTTAGACTGTCATG-1</th>\n",
              "      <th>ctrlTACTCTGACAGAGG-1</th>\n",
              "      <th>ctrlCTATGTTGGGATCT-1</th>\n",
              "      <th>ctrlACCGAAACGTGTAC-1</th>\n",
              "      <th>ctrlACTACTACACACCA-1</th>\n",
              "      <th>ctrlGAGTGACTGTGAGG-1</th>\n",
              "      <th>ctrlAGTTATGAGTAAAG-1</th>\n",
              "      <th>ctrlATGCACGATCCGTC-1</th>\n",
              "      <th>ctrlGAAGGGTGTGTGGT-1</th>\n",
              "      <th>...</th>\n",
              "      <th>ctrlGACGCCGAGCTGTA-1</th>\n",
              "      <th>ctrlGAGTACACCTGTGA-1</th>\n",
              "      <th>ctrlGTTCAACTACTGTG-1</th>\n",
              "      <th>ctrlTGATCACTATCGGT-1</th>\n",
              "      <th>ctrlGCTACAGATTCGTT-1</th>\n",
              "      <th>ctrlCAGTCAGATGTCCC-1</th>\n",
              "      <th>ctrlCACAACGACACTGA-1</th>\n",
              "      <th>ctrlTATAGATGGTGCTA-1</th>\n",
              "      <th>ctrlGCATGATGTGTGCA-1</th>\n",
              "      <th>ctrlCTTACATGAGGAGC-1</th>\n",
              "      <th>ctrlAGCCGGTGCTGAGT-1</th>\n",
              "      <th>ctrlCGCAGGACAAAGCA-1</th>\n",
              "      <th>ctrlGAAGCTACCCATAG-1</th>\n",
              "      <th>ctrlCTGACCACTGAGCT-1</th>\n",
              "      <th>ctrlTACGAGTGTTATCC-1</th>\n",
              "      <th>ctrlAATCTAGATAGCGT-1</th>\n",
              "      <th>ctrlTCGGCACTCCCACT-1</th>\n",
              "      <th>ctrlCCAGAAACTTCGGA-1</th>\n",
              "      <th>ctrlTCATGTACGCTTAG-1</th>\n",
              "      <th>ctrlATCGCGCTGGGAGT-1</th>\n",
              "      <th>ctrlGAGAGGTGGAATCC-1</th>\n",
              "      <th>ctrlATTCTGACTGAGGG-1</th>\n",
              "      <th>ctrlGACAGGGAACTGTG-1</th>\n",
              "      <th>ctrlGAGGACGACGATAC-1</th>\n",
              "      <th>ctrlAATCTAGATTCTAC-1</th>\n",
              "      <th>ctrlTAGTATGAGTACCA-1</th>\n",
              "      <th>ctrlCATCGGCTACCTTT-1</th>\n",
              "      <th>ctrlGACCTCTGGCTGTA-1</th>\n",
              "      <th>ctrlAAGACAGAGAACCT-1</th>\n",
              "      <th>ctrlAAATCATGCTCTAT-1</th>\n",
              "      <th>ctrlGGCTACCTGCAGAG-1</th>\n",
              "      <th>ctrlGATATAACGAATAG-1</th>\n",
              "      <th>ctrlACAAATTGACCTGA-1</th>\n",
              "      <th>ctrlGAGATCACTGCCTC-1</th>\n",
              "      <th>ctrlGCCATGCTATGCCA-1</th>\n",
              "      <th>ctrlCAAGTTCTACGACT-1</th>\n",
              "      <th>ctrlACAGTGACCTTCGC-1</th>\n",
              "      <th>ctrlAATCTCACGTATCG-1</th>\n",
              "      <th>ctrlAGGTGGGACTCGCT-1</th>\n",
              "      <th>ctrlCCAACCTGGTATGC-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene  ...  ctrlCCAACCTGGTATGC-1\n",
              "0  RP11.206L10.2  ...                     0\n",
              "1  RP11.206L10.9  ...                     0\n",
              "2      LINC00115  ...                     0\n",
              "3         FAM41C  ...                     0\n",
              "4          NOC2L  ...                     0\n",
              "\n",
              "[5 rows x 3001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIe3xYHSKHFR",
        "outputId": "28c51d27-9cf3-48f5-c3f0-6ca2d199d08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Shape of Ctrl: \", ctrl_sparse.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Ctrl:  (14879, 3001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeKqZb4XKlTj"
      },
      "source": [
        "ctr_E_df = ctrl_sparse.iloc[0:300, 0:1001]\n",
        "# convert to long format\n",
        "ctr_E_df_long = pd.melt(ctr_E_df, id_vars=['gene'],var_name='cell', value_name='expression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCsLD3nK_tf",
        "outputId": "272ea1c0-ff85-46ae-889c-d34f8a342e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "ctr_E_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>ctrlTCAGCGCTGGTCAT-1</th>\n",
              "      <th>ctrlTTATGGCTTCATTC-1</th>\n",
              "      <th>ctrlACCCACTGCTTAGG-1</th>\n",
              "      <th>ctrlATGGGTACCCCGTT-1</th>\n",
              "      <th>ctrlTGACTGGACAGTCA-1</th>\n",
              "      <th>ctrlGTGTAGTGGTTGTG-1</th>\n",
              "      <th>ctrlTGCGAAACGCATCA-1</th>\n",
              "      <th>ctrlTTCAACACTGAGGG-1</th>\n",
              "      <th>ctrlATTACCACGAATGA-1</th>\n",
              "      <th>ctrlACGCCACTTCTTTG-1</th>\n",
              "      <th>ctrlTAAGATTGAGTCAC-1</th>\n",
              "      <th>ctrlGACGCCGATTACCT-1</th>\n",
              "      <th>ctrlCTGATTTGACTAGC-1</th>\n",
              "      <th>ctrlCTACTCCTTGAGAA-1</th>\n",
              "      <th>ctrlATGTCGGATCACCC-1</th>\n",
              "      <th>ctrlATGGACACTGGGAG-1</th>\n",
              "      <th>ctrlCTGACAGAACTACG-1</th>\n",
              "      <th>ctrlAACTTGCTGGTGGA-1</th>\n",
              "      <th>ctrlAACAGAGACGTTGA-1</th>\n",
              "      <th>ctrlCATCGGCTATGTGC-1</th>\n",
              "      <th>ctrlTCTCTAGAACTTTC-1</th>\n",
              "      <th>ctrlCCACCTGAATACCG-1</th>\n",
              "      <th>ctrlTACTACTGGGCGAA-1</th>\n",
              "      <th>ctrlGCACACCTCTGTCC-1</th>\n",
              "      <th>ctrlGCTCAGCTAAACAG-1</th>\n",
              "      <th>ctrlTGCATGGAACGGTT-1</th>\n",
              "      <th>ctrlAAGGCTACTCTATC-1</th>\n",
              "      <th>ctrlGAAAGCCTTCTTAC-1</th>\n",
              "      <th>ctrlCGTTTAACGCTTCC-1</th>\n",
              "      <th>ctrlTCGGCACTGGTATC-1</th>\n",
              "      <th>ctrlCTTAGACTGTCATG-1</th>\n",
              "      <th>ctrlTACTCTGACAGAGG-1</th>\n",
              "      <th>ctrlCTATGTTGGGATCT-1</th>\n",
              "      <th>ctrlACCGAAACGTGTAC-1</th>\n",
              "      <th>ctrlACTACTACACACCA-1</th>\n",
              "      <th>ctrlGAGTGACTGTGAGG-1</th>\n",
              "      <th>ctrlAGTTATGAGTAAAG-1</th>\n",
              "      <th>ctrlATGCACGATCCGTC-1</th>\n",
              "      <th>ctrlGAAGGGTGTGTGGT-1</th>\n",
              "      <th>...</th>\n",
              "      <th>ctrlTACGCGCTTTTGGG-1</th>\n",
              "      <th>ctrlGTGTAGTGTCAGGT-1</th>\n",
              "      <th>ctrlGCCGAGTGACAGTC-1</th>\n",
              "      <th>ctrlTTGGAGACTGTTCT-1</th>\n",
              "      <th>ctrlAGGGTGGACACCAA-1</th>\n",
              "      <th>ctrlATCCTAACCAACTG-1</th>\n",
              "      <th>ctrlAATGATACCCTCGT-1</th>\n",
              "      <th>ctrlGGCGACACTCAGGT-1</th>\n",
              "      <th>ctrlGGCCGATGTATCGG-1</th>\n",
              "      <th>ctrlGAACAGCTATTCGG-1</th>\n",
              "      <th>ctrlATTCTGACGCTCCT-1</th>\n",
              "      <th>ctrlTTTAGAGAGGATCT-1</th>\n",
              "      <th>ctrlGGAGAGACTCGTGA-1</th>\n",
              "      <th>ctrlAGCCAATGACGTAC-1</th>\n",
              "      <th>ctrlTCAATAGATCCTGC-1</th>\n",
              "      <th>ctrlACGGAACTTATTCC-1</th>\n",
              "      <th>ctrlGACTGAACTCACGA-1</th>\n",
              "      <th>ctrlAGTAAGGAGGTCAT-1</th>\n",
              "      <th>ctrlCTTCATGACATTGG-1</th>\n",
              "      <th>ctrlCAGAAGCTTGTTCT-1</th>\n",
              "      <th>ctrlATGTAAACATGGTC-1</th>\n",
              "      <th>ctrlCTGATTTGAACCAC-1</th>\n",
              "      <th>ctrlCCCACATGGATACC-1</th>\n",
              "      <th>ctrlTGGATGTGGGACAG-1</th>\n",
              "      <th>ctrlTCAGGATGTGGTCA-1</th>\n",
              "      <th>ctrlAACCACGACCACCT-1</th>\n",
              "      <th>ctrlCCACTGTGTCAGGT-1</th>\n",
              "      <th>ctrlTCACCGTGAAGGTA-1</th>\n",
              "      <th>ctrlACAATCCTTCGACA-1</th>\n",
              "      <th>ctrlGAGGGTGAAAAGTG-1</th>\n",
              "      <th>ctrlTGCATGGATTCATC-1</th>\n",
              "      <th>ctrlTTCAGTTGTGGAGG-1</th>\n",
              "      <th>ctrlATACCTACATCGTG-1</th>\n",
              "      <th>ctrlCCATCCGATCTACT-1</th>\n",
              "      <th>ctrlTCAGTACTCTGAGT-1</th>\n",
              "      <th>ctrlAATCGGTGAAGTAG-1</th>\n",
              "      <th>ctrlATCTTGACGTCGAT-1</th>\n",
              "      <th>ctrlTCACCTCTACCCTC-1</th>\n",
              "      <th>ctrlTGACTTTGGGTTAC-1</th>\n",
              "      <th>ctrlTATCGACTGGTAGG-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene  ...  ctrlTATCGACTGGTAGG-1\n",
              "0  RP11.206L10.2  ...                     0\n",
              "1  RP11.206L10.9  ...                     0\n",
              "2      LINC00115  ...                     0\n",
              "3         FAM41C  ...                     0\n",
              "4          NOC2L  ...                     0\n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkyMJunX3eQq",
        "outputId": "fc7d4537-acba-43b4-99f5-aa7ab0888fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ctr_E_df_long.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>cell</th>\n",
              "      <th>expression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene                  cell  expression\n",
              "0  RP11.206L10.2  ctrlTCAGCGCTGGTCAT-1           0\n",
              "1  RP11.206L10.9  ctrlTCAGCGCTGGTCAT-1           0\n",
              "2      LINC00115  ctrlTCAGCGCTGGTCAT-1           0\n",
              "3         FAM41C  ctrlTCAGCGCTGGTCAT-1           0\n",
              "4          NOC2L  ctrlTCAGCGCTGGTCAT-1           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS0xeH4nLKrW",
        "outputId": "23a0ddb6-2db4-4378-e078-cb95e6d124ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(ctr_E_df_long == 0).astype(int).sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gene               0\n",
              "cell               0\n",
              "expression    286953\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDYsclCeLY13",
        "outputId": "7a35c0da-f8fc-40b2-f73e-c0df0c9455e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique genes: \", len((ctr_E_df_long['gene'].astype(\"category\").cat.codes).drop_duplicates()))#.sort_values()\n",
        "print(\"Unique cells: \",len((ctr_E_df_long['cell'].astype(\"category\").cat.codes).drop_duplicates()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique genes:  300\n",
            "Unique cells:  1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF77aCOvLmah"
      },
      "source": [
        "## **(2) Build Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60_GURI7LqOS"
      },
      "source": [
        "# process data set\n",
        "def process_dataset(df):\n",
        "\n",
        "    # Convert cells names into numerical IDs\n",
        "    df['cell_id'] = df['cell'].astype(\"category\").cat.codes\n",
        "    df['gene_id'] = df['gene'].astype(\"category\").cat.codes\n",
        "\n",
        "\n",
        "    gene_lookup = df[['gene_id', 'gene']].drop_duplicates()\n",
        "    gene_lookup['gene_id'] = gene_lookup.gene_id.astype(str)\n",
        "\n",
        "    # Grab the columns we need in the order we need them.\n",
        "    df = df[['cell_id', 'gene_id', 'expression']]\n",
        "\n",
        "\n",
        "    #df_train, df_test = train_test_split(df) # 80 20\n",
        "    df_train, df_test = df, ''\n",
        "\n",
        "\n",
        "\n",
        "    cells = list(np.sort(df.cell_id.unique()))\n",
        "    genes = list(np.sort(df.gene_id.unique()))\n",
        "\n",
        "\n",
        "    rows = df_train.cell_id.astype(int)\n",
        "    cols = df_train.gene_id.astype(int)\n",
        "\n",
        "    values = list(df_train.expression)\n",
        "\n",
        "    # Get all user ids and item ids.\n",
        "    cids = np.array(rows.tolist())\n",
        "    gids = np.array(cols.tolist())\n",
        "\n",
        "    # Sample 100 negative interactions for each cell in our test data\n",
        "    df_neg = '' #get_negatives(cids, gids, genes, df_test)\n",
        "\n",
        "    return cids, gids, df_train, df_test, df_neg, cells, genes, gene_lookup, values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OmveH4QLzkT"
      },
      "source": [
        "# sample a couple of negatives for each positive label\n",
        "def get_negatives(cids, gids, genes, df_test):\n",
        "\n",
        "    negativeList = []\n",
        "    test_c = df_test['cell_id'].values.tolist()\n",
        "    test_g = df_test['gene_id'].values.tolist()\n",
        "\n",
        "    test_expression_ids = list(zip(test_c, test_g))\n",
        "    zipped = set(zip(cids, gids))\n",
        "    #print(len(genes))\n",
        "\n",
        "    for (c, g) in test_expression_ids:\n",
        "        negatives = []\n",
        "        negatives.append((c, g))\n",
        "        for t in range(10):# increase for better accuracy\n",
        "            j = np.random.randint(len(genes)) # Get random gene id.\n",
        "            while (c, j) in zipped: # Check if there is an interaction\n",
        "                j = np.random.randint(len(genes)) # If yes, generate a new gene id\n",
        "            negatives.append(j) # Once a negative interaction is found we add it.\n",
        "            #print(\"J value is\", j)\n",
        "            #print(negatives)\n",
        "        negativeList.append(negatives)\n",
        "\n",
        "    df_neg = pd.DataFrame(negativeList)\n",
        "\n",
        "    return df_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yT-Sp8_MBAg"
      },
      "source": [
        "# mask the first gene to be used for testing\n",
        "def mask_first(x):\n",
        "    result = np.ones_like(x)\n",
        "    result[0] = 0\n",
        "\n",
        "    return result\n",
        "\n",
        "# split into train and test set\n",
        "def train_test_split(df):\n",
        "\n",
        "    df_test = df.copy(deep=True)\n",
        "    df_train = df.copy(deep=True)\n",
        "\n",
        "    df_test = df_test.groupby(['cell_id']).first()\n",
        "    df_test['cell_id'] = df_test.index\n",
        "    df_test = df_test[['cell_id', 'gene_id', 'expression']]\n",
        "    df_test.index.name = None\n",
        "\n",
        "    mask = df.groupby(['cell_id'])['cell_id'].transform(mask_first).astype(bool)\n",
        "    df_train = df.loc[mask]\n",
        "\n",
        "    return df_train, df_test\n",
        "\n",
        "# combine mask and train test split\n",
        "def get_train_instances():\n",
        "\n",
        "    cell_input, gene_input, labels = [],[],[]\n",
        "    zipped = set(zip(cids, gids))\n",
        "    #progress = tqdm(total=len(zipped))\n",
        "    #tracker = 0\n",
        "    for (c, g) in zip(cids, gids):\n",
        "        # Add our positive interaction\n",
        "        cell_input.append(c)\n",
        "        gene_input.append(g)\n",
        "        labels.append((df_train[(df_train.cell_id==c)&(df_train.gene_id==g)]).expression.values[0])\n",
        "        #labels.append(1)\n",
        "\n",
        "        # Sample a number of random negative interactions\n",
        "        for t in range(num_neg):\n",
        "            j = np.random.randint(len(genes))\n",
        "            #j = j if j!=32 else np.random.randint(len(genes)) # chainging to more than 1\n",
        "            while (c, j) in zipped:\n",
        "                j = np.random.randint(len(genes))\n",
        "                #j = rv+1 if rv==0 else rv\n",
        "            #print(\"gene value: \", j, \" cell value: \", c)\n",
        "            if j!=df_test.gene_id[0]:\n",
        "              cell_input.append(c)\n",
        "              gene_input.append(j)\n",
        "              #print(\"gene value: \", j, \" cell value: \", c)\n",
        "              #labels.append(0)\n",
        "              labels.append((df_train[(df_train.cell_id==c)&(df_train.gene_id==j)]).expression.values[0])\n",
        "        #progress.update(1)\n",
        "        #progress.set_description('Sampled Training Instance' + str(tracker+1))\n",
        "        #tracker+=1\n",
        "    #progress.close()\n",
        "    return cell_input, gene_input, labels\n",
        "\n",
        "# for faster training\n",
        "def random_mini_batches(C, G, L, mini_batch_size=20):\n",
        "\n",
        "    mini_batches = []\n",
        "\n",
        "    shuffled_C, shuffled_G, shuffled_L = shuffle(C, G, L, random_state=0)\n",
        "\n",
        "    num_complete_batches = int(math.floor(len(C)/mini_batch_size))\n",
        "    for k in range(0, num_complete_batches):\n",
        "        mini_batch_C = shuffled_C[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_G = shuffled_G[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_L = shuffled_L[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "\n",
        "        mini_batch = (mini_batch_C, mini_batch_G, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    if len(C) % mini_batch_size != 0:\n",
        "        mini_batch_C = shuffled_C[num_complete_batches * mini_batch_size: len(C)]\n",
        "        mini_batch_G = shuffled_G[num_complete_batches * mini_batch_size: len(C)]\n",
        "        mini_batch_L = shuffled_L[num_complete_batches * mini_batch_size: len(C)]\n",
        "\n",
        "        mini_batch = (mini_batch_C, mini_batch_G, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt-OkNr4NElH"
      },
      "source": [
        "# evaluation\n",
        "def get_hits(k_ranked, holdout):\n",
        "    for gene in k_ranked:\n",
        "        if gene == holdout:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def eval_rating(idx, test_expression, test_negatives, K):\n",
        "    # test_expression = test_expression_ids\n",
        "    map_gene_score = {}\n",
        "\n",
        "\n",
        "    genes = test_negatives[idx]\n",
        "\n",
        "\n",
        "    cell_idx = test_expression[idx][0]\n",
        "\n",
        "\n",
        "    holdout = test_expression[idx][1]\n",
        "    print(\"Holdout: \", holdout)\n",
        "\n",
        "\n",
        "    genes.append(holdout)\n",
        "\n",
        "\n",
        "    predict_cell = np.full(len(genes), cell_idx, dtype='int32').reshape(-1,1)\n",
        "    print(\"Predict cell: \", predict_cell)\n",
        "    np_genes = np.array(genes).reshape(-1,1)\n",
        "    print(\"Genes: \", genes)\n",
        "\n",
        "\n",
        "    predictions = session.run([output_layer], feed_dict={cell: predict_cell, gene: np_genes})\n",
        "    print(\"Predictions: \", predictions)\n",
        "\n",
        "    predictions = predictions[0].flatten().tolist()\n",
        "\n",
        "\n",
        "    for i in range(len(genes)):\n",
        "        current_gene = genes[i]\n",
        "        map_gene_score[current_gene] = predictions[i]\n",
        "\n",
        "\n",
        "    k_ranked = heapq.nlargest(K, map_gene_score, key=map_gene_score.get)\n",
        "    print(\"K Ranked: \", k_ranked)\n",
        "\n",
        "\n",
        "    hits = get_hits(k_ranked, holdout)\n",
        "\n",
        "    return hits\n",
        "\n",
        "#\n",
        "def evaluate(df_neg, K=10):\n",
        "\n",
        "    hits = []\n",
        "\n",
        "    test_c = df_test['cell_id'].values.tolist()\n",
        "    test_g = df_test['gene_id'].values.tolist()\n",
        "\n",
        "    test_expression_ids = list(zip(test_c, test_g))\n",
        "\n",
        "    df_neg = df_neg.drop(df_neg.columns[0], axis=1)\n",
        "    test_negatives = df_neg.values.tolist()\n",
        "    #len(test_expression)-2\n",
        "    for idx in range(len(test_expression_ids)):\n",
        "        # For each idx, call eval_one_rating\n",
        "        hitrate = eval_rating(idx, test_expression_ids, test_negatives, K)\n",
        "        hits.append(hitrate)\n",
        "\n",
        "    return hits\n",
        "\n",
        "\n",
        "def poisson_loss(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    f1 = tf.multiply(y_true, tf.log(tf.add(y_pred, 1e-10)))\n",
        "    nice_bound = tf.add(tf.lgamma(y_pred), 1)\n",
        "    fbound = tf.subtract(f1, nice_bound)\n",
        "    return tf.reduce_mean(tf.square(tf.subtract(y_pred, fbound)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDDYxAeHNUr7"
      },
      "source": [
        "def make_recommendation(cell_ids=None, gene_ids = None, top=None):\n",
        "    # make recommendations for all\n",
        "    df = pd.DataFrame()\n",
        "    df[\"Gene\"] = (ctr_E_df_long.gene_id).unique()\n",
        "    for cell_idx in np.sort((ctr_E_df_long.cell_id).unique()):\n",
        "        # get the genes for the given cell\n",
        "        genes = ((ctr_E_df_long[ctr_E_df_long.cell_id==cell_idx]).gene_id).values\n",
        "        #cell_ls = [cell_idx]# * len(genes)\n",
        "        # create a full gene prediction for a cell\n",
        "        predict_cell = np.full(len(genes), cell_idx, dtype='int32').reshape(-1,1)\n",
        "        np_genes = np.array(genes).reshape(-1,1)\n",
        "\n",
        "        #run with the given session\n",
        "        predictions = session.run([output_layer], feed_dict={cell: predict_cell, gene: np_genes})\n",
        "        #print(\"Predictions: \", predictions)\n",
        "\n",
        "        predictions = predictions[0].flatten().tolist()\n",
        "        df[cell_idx] = predictions\n",
        "\n",
        "    return df\n",
        "\n",
        "# try basic k-means clustering\n",
        "def kMeans_clustering(k=10):\n",
        "  kmeans_labels = cluster.KMeans(n_clusters=k).fit_predict(mlp_df)\n",
        "  standard_embedding = umap.UMAP(random_state=42).fit_transform(mlp_df)\n",
        "  newdf = pd.DataFrame(standard_embedding, columns = [\"x1\", \"x2\"])\n",
        "  newdf[\"cluster\"] = kmeans_labels\n",
        "  # make the plot\n",
        "  size = 80\n",
        "  plt.figure(figsize=(16,10))\n",
        "  sc = plt.scatter(newdf['x1'], newdf['x2'], s=size, c=newdf['cluster'], edgecolors='none')\n",
        "\n",
        "  lp = lambda i: plt.plot([],color=sc.cmap(sc.norm(i)), ms=np.sqrt(size), mec=\"none\",\n",
        "                          label=\"Cluster {:g}\".format(i), ls=\"\", marker=\"o\")[0]\n",
        "  handles = [lp(i) for i in np.unique(newdf[\"cluster\"])]\n",
        "  plt.legend(handles=handles)\n",
        "  plt.xlabel(\"Umap 1\")\n",
        "  plt.ylabel(\"Umap 2\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucy3A3s6S4xg"
      },
      "source": [
        "cids, gids, df_train, df_test, df_neg, cells, genes, gene_lookup, values = process_dataset(ctr_E_df_long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO-14hk4Tw2n",
        "outputId": "b9916050-01b3-4d1f-d799-646d8bfdc0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique train genes: \", len((df_train['gene_id']).drop_duplicates()))\n",
        "print(\"Unique train cells: \", len((df_train['cell_id']).drop_duplicates()))\n",
        "#print(\"Unique test genes: \", len((df_test['gene_id']).drop_duplicates()))\n",
        "#print(\"Unique test cells: \",len((df_test['cell_id']).drop_duplicates()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique train genes:  300\n",
            "Unique train cells:  1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdIBDZFq6TKR",
        "outputId": "6703f071-0fa9-44d6-f5f7-ac1d97bbc0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>gene_id</th>\n",
              "      <th>expression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>197</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>856</td>\n",
              "      <td>198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>856</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>856</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>856</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cell_id  gene_id  expression\n",
              "0      856      197           0\n",
              "1      856      198           0\n",
              "2      856      115           0\n",
              "3      856       79           0\n",
              "4      856      147           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqqkJoYBG7tB",
        "outputId": "ca711c89-3b2e-470a-bb40-eccd59c1160f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# check for infinite and nullvalues\n",
        "print(\"Has null values? : \", df_train.isnull().values.any())\n",
        "np.isnan(df_train).any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Has null values? :  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cell_id       False\n",
              "gene_id       False\n",
              "expression    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-aJ-IwDn7HB"
      },
      "source": [
        "### **(3) Set Training Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U-WWuSBVplW"
      },
      "source": [
        "# define learning parameters\n",
        "num_neg = 4\n",
        "epochs = 20\n",
        "# 32, 64, 128, 256,\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "latent_features = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZDtvIMtV8UF"
      },
      "source": [
        "# get train instances\n",
        "cell_input, gene_input, labels = cids, gids, values#get_train_instances()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrbQKH5VKfXj"
      },
      "source": [
        "#sum(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPYghEET6Co"
      },
      "source": [
        "### (4) **Build & Train MLP Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q_VFxWKT9nV"
      },
      "source": [
        "graph = tf.Graph() # tensorflow term for building a pipeline\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    # define input placeholders for cell, gene and count=label.\n",
        "    cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "    # cell feature embedding\n",
        "    c_var = tf.Variable(tf.random_uniform([len(cells), 20], minval= 0), name='cell_embedding')\n",
        "    cell_embedding = tf.nn.embedding_lookup(c_var, cell) # for each cell id, return a vector of length 20\n",
        "\n",
        "    # gene feature embedding\n",
        "    g_var = tf.Variable(tf.random_uniform([len(genes), 20], minval= 0), name='gene_embedding')\n",
        "    gene_embedding = tf.nn.embedding_lookup(g_var, gene) # for each gene id, return a vector of length 20\n",
        "\n",
        "    # Flatten our cell and gene embeddings.\n",
        "    cell_embedding = tf.keras.layers.Flatten()(cell_embedding)\n",
        "    gene_embedding = tf.keras.layers.Flatten()(gene_embedding)\n",
        "\n",
        "    # concatenate the two embedding vectors\n",
        "    concatenated = tf.keras.layers.concatenate([cell_embedding, gene_embedding])\n",
        "\n",
        "\n",
        "    # add a first dropout layer.\n",
        "    dropout = tf.keras.layers.Dropout(0.2)(concatenated)\n",
        "\n",
        "    # add four hidden layers along with batch\n",
        "    # normalization and dropouts. use relu as the activation function.\n",
        "    layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(dropout)\n",
        "    batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_1)\n",
        "    dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm1)\n",
        "\n",
        "    layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(layer_1)\n",
        "    batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_2)\n",
        "    dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm2)\n",
        "\n",
        "    layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(layer_2)\n",
        "    layer_4 = tf.keras.layers.Dense(8, activation='exponential', name='layer4')(layer_3) # make linear\n",
        "\n",
        "    # final single neuron output layer.\n",
        "    output_layer = tf.keras.layers.Dense(1,\n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(layer_4)\n",
        "\n",
        "    # our loss function as mse.\n",
        "    labels = tf.cast(label, tf.float32)\n",
        "    #print(labels)\n",
        "    logits = output_layer\n",
        "    #tf.print(logits)\n",
        "    #loss =  poisson_loss(labels, logits) #tf.nn.log_poisson_loss(labels, logits)\n",
        "    loss = poisson_loss(labels, logits)\n",
        "    #print(loss)\n",
        "\n",
        "    # train using the Adam optimizer to minimize loss.\n",
        "    opt = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # initialize all tensorflow variables.\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-pUtYfRV21l"
      },
      "source": [
        "# for epoch in range(epochs):\n",
        "\n",
        "#     # Get our training input.\n",
        "#     cell_input, gene_input, labels = cids, gids, values  #get_train_instances()\n",
        "\n",
        "#     # Generate a list of minibatches.\n",
        "#     minibatches = random_mini_batches(cell_input, gene_input, labels)\n",
        "\n",
        "#     # This has noting to do with tensorflow but gives\n",
        "#     # us a nice progress bar for the training\n",
        "#     progress = tqdm(total=len(minibatches))\n",
        "\n",
        "#     # Loop over each batch and feed our cells, genes and labels\n",
        "#     # into our graph.\n",
        "#     for minibatch in minibatches:\n",
        "#         feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "#                     gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "#                     label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "\n",
        "#         # Execute the graph.\n",
        "#         _, l = session.run([step, loss], feed_dict)\n",
        "#         # Update the progress\n",
        "#         progress.update(1)\n",
        "#         progress.set_description('Epoch: %d - Loss: %.8f' % (epoch+1, l))\n",
        "\n",
        "#     progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chDk0bQJeFXd"
      },
      "source": [
        "# mlp_df = make_recommendation()\n",
        "# #mlp_df.drop('Gene', axis=1, inplace=True)\n",
        "# mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfNnaRTjg8MY"
      },
      "source": [
        "# # try basic clustering\n",
        "# kMeans_clustering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOeD4NHFlFTN"
      },
      "source": [
        "### **(5) Build & Train GMF Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQzTybLklIHI"
      },
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "\n",
        "    c_var = tf.Variable(tf.random_uniform([len(cells), latent_features],\n",
        "                                         minval =0.0), name='cell_embedding')\n",
        "    cell_embedding = tf.nn.embedding_lookup(c_var, cell)\n",
        "\n",
        "\n",
        "    g_var = tf.Variable(tf.random_uniform([len(genes), latent_features],\n",
        "                                         minval=0.0), name='gene_embedding')\n",
        "    gene_embedding = tf.nn.embedding_lookup(g_var, gene)\n",
        "\n",
        "    # flatten the embeddings\n",
        "    cell_embedding = tf.keras.layers.Flatten()(cell_embedding)\n",
        "    gene_embedding = tf.keras.layers.Flatten()(gene_embedding)\n",
        "\n",
        "    # multiplying our cell and gene latent space vectors together\n",
        "    prediction_matrix = tf.multiply(cell_embedding, gene_embedding)\n",
        "\n",
        "\n",
        "    output_layer = tf.keras.layers.Dense(1,\n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(prediction_matrix)\n",
        "\n",
        "    # loss function as mse.\n",
        "    labels = tf.cast(label, tf.float32)\n",
        "    loss = poisson_loss(labels, output_layer) #tf.reduce_mean(tf.square(tf.subtract(labels, output_layer)))\n",
        "\n",
        "    # using the Adam optimizer to minimize loss.\n",
        "    opt = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # initialize all tensorflow variables.\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOQohQDylMiv"
      },
      "source": [
        "# for epoch in range(epochs):\n",
        "\n",
        "#     # Get our training input.\n",
        "#     cell_input, gene_input, labels = get_train_instances()\n",
        "\n",
        "#     # Generate a list of minibatches.\n",
        "#     minibatches = random_mini_batches(cell_input, gene_input, labels)\n",
        "\n",
        "#     # This has noting to do with tensorflow but gives\n",
        "#     # us a nice progress bar for the training\n",
        "#     progress = tqdm(total=len(minibatches))\n",
        "\n",
        "#     # Loop over each batch and feed our cells, genes and labels\n",
        "#     # into our graph.\n",
        "#     for minibatch in minibatches:\n",
        "#         feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "#                     gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "#                     label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "\n",
        "#         # Execute the graph.\n",
        "#         _, l = session.run([step, loss], feed_dict)\n",
        "\n",
        "#         # Update the progress\n",
        "#         progress.update(1)\n",
        "#         progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "#     progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K67wuFY8lU_c"
      },
      "source": [
        "# mlp_df = make_recommendation()\n",
        "# mlp_df.drop('Gene', axis=1, inplace=True)\n",
        "# mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRXldjylV6t"
      },
      "source": [
        "# # try basic clustering\n",
        "# kMeans_clustering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4RXauN3lWqX"
      },
      "source": [
        "### **(6) Build & Train Combined NeuMF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxpB2gGOlalr"
      },
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "\n",
        "    mlp_c_var = tf.Variable(tf.random_uniform([len(cells), latent_features], minval=0), name='mlp_cell_embedding')\n",
        "    mlp_cell_embedding = tf.nn.embedding_lookup(mlp_c_var, cell)\n",
        "\n",
        "\n",
        "    mlp_g_var = tf.Variable(tf.random_uniform([len(genes), latent_features], minval=0), name='mlp_gene_embedding')\n",
        "    mlp_gene_embedding = tf.nn.embedding_lookup(mlp_g_var, gene)\n",
        "\n",
        "\n",
        "    gmf_c_var = tf.Variable(tf.random_uniform([len(cells), latent_features], minval=0), name='gmf_cell_embedding')\n",
        "    gmf_cell_embedding = tf.nn.embedding_lookup(gmf_c_var, cell)\n",
        "\n",
        "    # gene embedding for GMF\n",
        "    gmf_g_var = tf.Variable(tf.random_uniform([len(genes), latent_features], minval=0), name='gmf_item_embedding')\n",
        "    gmf_gene_embedding = tf.nn.embedding_lookup(gmf_g_var, gene)\n",
        "\n",
        "    # flatten gmf embedding\n",
        "    gmf_cell_embed = tf.keras.layers.Flatten()(gmf_cell_embedding)\n",
        "    gmf_gene_embed = tf.keras.layers.Flatten()(gmf_gene_embedding)\n",
        "    gmf_matrix = tf.multiply(gmf_cell_embed, gmf_gene_embed)\n",
        "\n",
        "    # flatten mlp embedding\n",
        "    mlp_cell_embed = tf.keras.layers.Flatten()(mlp_cell_embedding)\n",
        "    mlp_gene_embed = tf.keras.layers.Flatten()(mlp_gene_embedding)\n",
        "    mlp_concat = tf.keras.layers.concatenate([mlp_cell_embed, mlp_gene_embed])\n",
        "\n",
        "    mlp_dropout = tf.keras.layers.Dropout(0.2)(mlp_concat)\n",
        "\n",
        "    mlp_layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(mlp_dropout)\n",
        "    mlp_batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_1)\n",
        "    mlp_dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm1)\n",
        "\n",
        "    mlp_layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(mlp_dropout1)\n",
        "    mlp_batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_2)\n",
        "    mlp_dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm2)\n",
        "\n",
        "    mlp_layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(mlp_dropout2)\n",
        "    mlp_layer_4 = tf.keras.layers.Dense(8, activation='exponential', name='layer4')(mlp_layer_3)\n",
        "\n",
        "    # We merge the two networks together\n",
        "    merged_vector = tf.keras.layers.concatenate([gmf_matrix, mlp_layer_4])\n",
        "\n",
        "    # Our final single neuron output layer.\n",
        "    output_layer = tf.keras.layers.Dense(1,\n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(merged_vector)\n",
        "\n",
        "    # Our loss function as mse.\n",
        "    labels = tf.cast(label, tf.float32)\n",
        "    loss = tf.reduce_mean(tf.square(tf.subtract(\n",
        "                labels,\n",
        "                output_layer)))\n",
        "    #loss = poisson_loss(labels, output_layer)\n",
        "\n",
        "    # Train using the Adam optimizer to minimize our loss.\n",
        "    opt = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon=1)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # Initialize all tensorflow variables.\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BNFsRL2lgkw",
        "outputId": "a7be253e-628a-4e6e-8960-d416f63e0b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    # Get our training input.\n",
        "    cell_input, gene_input, labels = cids, gids, values #get_train_instances()\n",
        "\n",
        "    # Generate a list of minibatches.\n",
        "    minibatches = random_mini_batches(cell_input, gene_input, labels)\n",
        "\n",
        "    # This has noting to do with tensorflow but gives\n",
        "    # us a nice progress bar for the training\n",
        "    progress = tqdm(total=len(minibatches))\n",
        "\n",
        "    # Loop over each batch and feed our cells, genes and labels\n",
        "    # into our graph.\n",
        "    for minibatch in minibatches:\n",
        "        feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "                    gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "                    label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "\n",
        "        # Execute the graph.\n",
        "        _, l = session.run([step, loss], feed_dict)\n",
        "        # Update the progress\n",
        "        progress.update(1)\n",
        "        progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "    progress.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Loss: 0.068: 100%|██████████| 15000/15000 [00:59<00:00, 251.11it/s]\n",
            "Epoch: 2 - Loss: 0.059: 100%|██████████| 15000/15000 [00:58<00:00, 255.50it/s]\n",
            "Epoch: 3 - Loss: 0.049: 100%|██████████| 15000/15000 [00:59<00:00, 254.01it/s]\n",
            "Epoch: 4 - Loss: 0.048: 100%|██████████| 15000/15000 [00:58<00:00, 255.38it/s]\n",
            "Epoch: 5 - Loss: 0.047: 100%|██████████| 15000/15000 [00:58<00:00, 258.05it/s]\n",
            "Epoch: 6 - Loss: 0.046: 100%|██████████| 15000/15000 [01:00<00:00, 246.44it/s]\n",
            "Epoch: 7 - Loss: 0.046: 100%|██████████| 15000/15000 [00:59<00:00, 251.01it/s]\n",
            "Epoch: 8 - Loss: 0.046: 100%|██████████| 15000/15000 [01:00<00:00, 246.07it/s]\n",
            "Epoch: 9 - Loss: 0.046: 100%|██████████| 15000/15000 [00:59<00:00, 250.42it/s]\n",
            "Epoch: 10 - Loss: 0.046: 100%|██████████| 15000/15000 [00:59<00:00, 250.01it/s]\n",
            "Epoch: 11 - Loss: 0.046: 100%|██████████| 15000/15000 [00:59<00:00, 252.08it/s]\n",
            "Epoch: 12 - Loss: 0.047: 100%|██████████| 15000/15000 [01:00<00:00, 248.95it/s]\n",
            "Epoch: 13 - Loss: 0.047: 100%|██████████| 15000/15000 [01:00<00:00, 246.45it/s]\n",
            "Epoch: 14 - Loss: 0.048: 100%|██████████| 15000/15000 [01:00<00:00, 246.43it/s]\n",
            "Epoch: 15 - Loss: 0.049: 100%|██████████| 15000/15000 [00:58<00:00, 255.64it/s]\n",
            "Epoch: 16 - Loss: 0.049: 100%|██████████| 15000/15000 [01:02<00:00, 238.44it/s]\n",
            "Epoch: 17 - Loss: 0.050: 100%|██████████| 15000/15000 [00:59<00:00, 250.79it/s]\n",
            "Epoch: 18 - Loss: 0.050: 100%|██████████| 15000/15000 [00:59<00:00, 252.21it/s]\n",
            "Epoch: 19 - Loss: 0.050: 100%|██████████| 15000/15000 [00:59<00:00, 250.41it/s]\n",
            "Epoch: 20 - Loss: 0.051: 100%|██████████| 15000/15000 [01:00<00:00, 247.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y3T7VEF07gY",
        "outputId": "f17de904-2830-4814-eeda-519fc6611299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "mlp_df = make_recommendation()\n",
        "#mlp_df.drop('Gene', axis=1, inplace=True) #uncomment to cluster but comment out when writing out to csv file.\n",
        "mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>960</th>\n",
              "      <th>961</th>\n",
              "      <th>962</th>\n",
              "      <th>963</th>\n",
              "      <th>964</th>\n",
              "      <th>965</th>\n",
              "      <th>966</th>\n",
              "      <th>967</th>\n",
              "      <th>968</th>\n",
              "      <th>969</th>\n",
              "      <th>970</th>\n",
              "      <th>971</th>\n",
              "      <th>972</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>979</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>197</td>\n",
              "      <td>0.036639</td>\n",
              "      <td>0.092944</td>\n",
              "      <td>0.017719</td>\n",
              "      <td>0.004090</td>\n",
              "      <td>0.037086</td>\n",
              "      <td>0.082234</td>\n",
              "      <td>0.070179</td>\n",
              "      <td>0.039186</td>\n",
              "      <td>0.003899</td>\n",
              "      <td>-0.027535</td>\n",
              "      <td>0.067477</td>\n",
              "      <td>0.050639</td>\n",
              "      <td>0.074633</td>\n",
              "      <td>-0.025847</td>\n",
              "      <td>0.016262</td>\n",
              "      <td>0.031445</td>\n",
              "      <td>0.018563</td>\n",
              "      <td>0.021477</td>\n",
              "      <td>0.011538</td>\n",
              "      <td>0.024727</td>\n",
              "      <td>0.001599</td>\n",
              "      <td>0.097609</td>\n",
              "      <td>-0.000339</td>\n",
              "      <td>0.010691</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>-0.008409</td>\n",
              "      <td>0.027736</td>\n",
              "      <td>0.030254</td>\n",
              "      <td>0.024285</td>\n",
              "      <td>0.064677</td>\n",
              "      <td>0.029624</td>\n",
              "      <td>0.053575</td>\n",
              "      <td>0.016353</td>\n",
              "      <td>0.074770</td>\n",
              "      <td>0.040264</td>\n",
              "      <td>0.059566</td>\n",
              "      <td>0.011013</td>\n",
              "      <td>0.080908</td>\n",
              "      <td>0.014295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055771</td>\n",
              "      <td>0.032188</td>\n",
              "      <td>0.004367</td>\n",
              "      <td>0.004829</td>\n",
              "      <td>-0.006842</td>\n",
              "      <td>-0.028909</td>\n",
              "      <td>-0.010713</td>\n",
              "      <td>0.016640</td>\n",
              "      <td>0.142138</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.024171</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>0.030605</td>\n",
              "      <td>0.071365</td>\n",
              "      <td>0.070735</td>\n",
              "      <td>0.064082</td>\n",
              "      <td>0.070764</td>\n",
              "      <td>0.030024</td>\n",
              "      <td>0.030632</td>\n",
              "      <td>0.035773</td>\n",
              "      <td>0.011779</td>\n",
              "      <td>0.016384</td>\n",
              "      <td>0.015905</td>\n",
              "      <td>0.042527</td>\n",
              "      <td>0.039873</td>\n",
              "      <td>-0.001428</td>\n",
              "      <td>0.081128</td>\n",
              "      <td>0.049123</td>\n",
              "      <td>0.044698</td>\n",
              "      <td>0.008061</td>\n",
              "      <td>-0.008430</td>\n",
              "      <td>0.039914</td>\n",
              "      <td>0.075403</td>\n",
              "      <td>0.027647</td>\n",
              "      <td>-0.023651</td>\n",
              "      <td>0.015182</td>\n",
              "      <td>0.059195</td>\n",
              "      <td>-0.005199</td>\n",
              "      <td>0.018271</td>\n",
              "      <td>0.061782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>-0.025610</td>\n",
              "      <td>0.050843</td>\n",
              "      <td>0.016639</td>\n",
              "      <td>-0.028515</td>\n",
              "      <td>-0.000713</td>\n",
              "      <td>-0.008155</td>\n",
              "      <td>-0.031553</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>-0.033002</td>\n",
              "      <td>-0.030404</td>\n",
              "      <td>0.005078</td>\n",
              "      <td>-0.028374</td>\n",
              "      <td>-0.034297</td>\n",
              "      <td>-0.046268</td>\n",
              "      <td>0.015734</td>\n",
              "      <td>-0.000144</td>\n",
              "      <td>-0.055746</td>\n",
              "      <td>-0.017775</td>\n",
              "      <td>-0.006589</td>\n",
              "      <td>-0.018774</td>\n",
              "      <td>0.037726</td>\n",
              "      <td>-0.011113</td>\n",
              "      <td>-0.038167</td>\n",
              "      <td>-0.037632</td>\n",
              "      <td>-0.010732</td>\n",
              "      <td>-0.094329</td>\n",
              "      <td>-0.024566</td>\n",
              "      <td>-0.018998</td>\n",
              "      <td>-0.039822</td>\n",
              "      <td>0.022876</td>\n",
              "      <td>0.004221</td>\n",
              "      <td>-0.076686</td>\n",
              "      <td>-0.031294</td>\n",
              "      <td>0.034499</td>\n",
              "      <td>0.002949</td>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.016795</td>\n",
              "      <td>0.015543</td>\n",
              "      <td>-0.017204</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031233</td>\n",
              "      <td>-0.002093</td>\n",
              "      <td>-0.032195</td>\n",
              "      <td>-0.019652</td>\n",
              "      <td>0.005359</td>\n",
              "      <td>-0.044990</td>\n",
              "      <td>-0.014767</td>\n",
              "      <td>-0.022163</td>\n",
              "      <td>0.033890</td>\n",
              "      <td>-0.015185</td>\n",
              "      <td>-0.021785</td>\n",
              "      <td>-0.018911</td>\n",
              "      <td>-0.010840</td>\n",
              "      <td>0.046623</td>\n",
              "      <td>-0.005980</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>0.030772</td>\n",
              "      <td>-0.012059</td>\n",
              "      <td>-0.048766</td>\n",
              "      <td>-0.008874</td>\n",
              "      <td>-0.029673</td>\n",
              "      <td>-0.022575</td>\n",
              "      <td>-0.023069</td>\n",
              "      <td>0.033593</td>\n",
              "      <td>-0.016188</td>\n",
              "      <td>-0.074370</td>\n",
              "      <td>0.025871</td>\n",
              "      <td>-0.025156</td>\n",
              "      <td>-0.004763</td>\n",
              "      <td>-0.042599</td>\n",
              "      <td>-0.002922</td>\n",
              "      <td>-0.055974</td>\n",
              "      <td>-0.009948</td>\n",
              "      <td>-0.035844</td>\n",
              "      <td>-0.031628</td>\n",
              "      <td>-0.031933</td>\n",
              "      <td>0.035979</td>\n",
              "      <td>-0.014246</td>\n",
              "      <td>0.025826</td>\n",
              "      <td>0.019763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>0.046969</td>\n",
              "      <td>0.002236</td>\n",
              "      <td>-0.028554</td>\n",
              "      <td>0.025345</td>\n",
              "      <td>0.045571</td>\n",
              "      <td>0.013095</td>\n",
              "      <td>-0.029933</td>\n",
              "      <td>-0.011078</td>\n",
              "      <td>-0.041085</td>\n",
              "      <td>-0.007335</td>\n",
              "      <td>-0.008253</td>\n",
              "      <td>-0.004582</td>\n",
              "      <td>-0.030446</td>\n",
              "      <td>-0.030229</td>\n",
              "      <td>0.006740</td>\n",
              "      <td>-0.026855</td>\n",
              "      <td>-0.050712</td>\n",
              "      <td>-0.014198</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.010182</td>\n",
              "      <td>0.028247</td>\n",
              "      <td>-0.040066</td>\n",
              "      <td>-0.011025</td>\n",
              "      <td>-0.007845</td>\n",
              "      <td>-0.017418</td>\n",
              "      <td>-0.015575</td>\n",
              "      <td>-0.046104</td>\n",
              "      <td>-0.029175</td>\n",
              "      <td>0.053414</td>\n",
              "      <td>0.027062</td>\n",
              "      <td>-0.033163</td>\n",
              "      <td>-0.028492</td>\n",
              "      <td>0.010570</td>\n",
              "      <td>0.006171</td>\n",
              "      <td>0.019176</td>\n",
              "      <td>-0.006459</td>\n",
              "      <td>0.031299</td>\n",
              "      <td>-0.041672</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001315</td>\n",
              "      <td>-0.027199</td>\n",
              "      <td>-0.041779</td>\n",
              "      <td>-0.026356</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>-0.051723</td>\n",
              "      <td>-0.050844</td>\n",
              "      <td>-0.004241</td>\n",
              "      <td>0.023207</td>\n",
              "      <td>0.002028</td>\n",
              "      <td>-0.004456</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>0.003474</td>\n",
              "      <td>0.005633</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>-0.006969</td>\n",
              "      <td>0.021987</td>\n",
              "      <td>-0.034356</td>\n",
              "      <td>-0.043121</td>\n",
              "      <td>0.020410</td>\n",
              "      <td>-0.035437</td>\n",
              "      <td>-0.032658</td>\n",
              "      <td>-0.051656</td>\n",
              "      <td>0.006144</td>\n",
              "      <td>0.013671</td>\n",
              "      <td>-0.034114</td>\n",
              "      <td>0.021069</td>\n",
              "      <td>-0.034230</td>\n",
              "      <td>0.012056</td>\n",
              "      <td>-0.026112</td>\n",
              "      <td>-0.042409</td>\n",
              "      <td>-0.049812</td>\n",
              "      <td>0.002354</td>\n",
              "      <td>-0.006291</td>\n",
              "      <td>-0.038264</td>\n",
              "      <td>-0.025707</td>\n",
              "      <td>0.045566</td>\n",
              "      <td>-0.019954</td>\n",
              "      <td>0.023893</td>\n",
              "      <td>0.015411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.048009</td>\n",
              "      <td>0.038906</td>\n",
              "      <td>0.016099</td>\n",
              "      <td>0.039357</td>\n",
              "      <td>0.057570</td>\n",
              "      <td>0.003184</td>\n",
              "      <td>-0.035963</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.010310</td>\n",
              "      <td>0.010559</td>\n",
              "      <td>0.012427</td>\n",
              "      <td>0.009836</td>\n",
              "      <td>-0.034234</td>\n",
              "      <td>0.005382</td>\n",
              "      <td>-0.007997</td>\n",
              "      <td>-0.082064</td>\n",
              "      <td>0.033862</td>\n",
              "      <td>-0.011630</td>\n",
              "      <td>-0.025513</td>\n",
              "      <td>0.025898</td>\n",
              "      <td>-0.047223</td>\n",
              "      <td>-0.026969</td>\n",
              "      <td>-0.004900</td>\n",
              "      <td>0.001972</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>-0.034460</td>\n",
              "      <td>-0.038198</td>\n",
              "      <td>0.106237</td>\n",
              "      <td>0.036404</td>\n",
              "      <td>-0.039151</td>\n",
              "      <td>-0.035227</td>\n",
              "      <td>0.060047</td>\n",
              "      <td>-0.008112</td>\n",
              "      <td>0.060250</td>\n",
              "      <td>0.029123</td>\n",
              "      <td>0.052117</td>\n",
              "      <td>-0.026153</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024462</td>\n",
              "      <td>0.006808</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>-0.008336</td>\n",
              "      <td>0.008581</td>\n",
              "      <td>-0.016987</td>\n",
              "      <td>-0.019223</td>\n",
              "      <td>-0.017421</td>\n",
              "      <td>0.037360</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>-0.027903</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>0.044584</td>\n",
              "      <td>0.037614</td>\n",
              "      <td>0.019072</td>\n",
              "      <td>0.008207</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>0.010595</td>\n",
              "      <td>-0.011268</td>\n",
              "      <td>0.036166</td>\n",
              "      <td>-0.015930</td>\n",
              "      <td>0.016926</td>\n",
              "      <td>-0.035063</td>\n",
              "      <td>0.006447</td>\n",
              "      <td>0.038164</td>\n",
              "      <td>0.005289</td>\n",
              "      <td>0.060096</td>\n",
              "      <td>-0.033465</td>\n",
              "      <td>-0.021912</td>\n",
              "      <td>0.079499</td>\n",
              "      <td>0.027543</td>\n",
              "      <td>-0.011947</td>\n",
              "      <td>-0.016437</td>\n",
              "      <td>0.024556</td>\n",
              "      <td>0.002304</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>0.038563</td>\n",
              "      <td>0.014004</td>\n",
              "      <td>-0.007221</td>\n",
              "      <td>0.042276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>147</td>\n",
              "      <td>0.021828</td>\n",
              "      <td>0.017569</td>\n",
              "      <td>-0.008736</td>\n",
              "      <td>0.009350</td>\n",
              "      <td>0.021692</td>\n",
              "      <td>0.072568</td>\n",
              "      <td>-0.007108</td>\n",
              "      <td>-0.010800</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>-0.017035</td>\n",
              "      <td>0.042744</td>\n",
              "      <td>0.004313</td>\n",
              "      <td>0.020046</td>\n",
              "      <td>0.025905</td>\n",
              "      <td>-0.027094</td>\n",
              "      <td>0.019551</td>\n",
              "      <td>-0.024255</td>\n",
              "      <td>-0.018905</td>\n",
              "      <td>-0.005175</td>\n",
              "      <td>-0.007059</td>\n",
              "      <td>-0.024189</td>\n",
              "      <td>0.024368</td>\n",
              "      <td>-0.032195</td>\n",
              "      <td>0.011082</td>\n",
              "      <td>-0.008827</td>\n",
              "      <td>-0.038442</td>\n",
              "      <td>-0.001910</td>\n",
              "      <td>-0.005505</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>0.035774</td>\n",
              "      <td>0.038373</td>\n",
              "      <td>0.001885</td>\n",
              "      <td>-0.018637</td>\n",
              "      <td>0.020231</td>\n",
              "      <td>-0.000769</td>\n",
              "      <td>0.061754</td>\n",
              "      <td>0.016242</td>\n",
              "      <td>0.044476</td>\n",
              "      <td>-0.031664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005807</td>\n",
              "      <td>-0.021768</td>\n",
              "      <td>-0.051396</td>\n",
              "      <td>-0.012531</td>\n",
              "      <td>0.006009</td>\n",
              "      <td>-0.051057</td>\n",
              "      <td>-0.021083</td>\n",
              "      <td>-0.001427</td>\n",
              "      <td>0.034554</td>\n",
              "      <td>0.004729</td>\n",
              "      <td>-0.025193</td>\n",
              "      <td>-0.024674</td>\n",
              "      <td>0.028102</td>\n",
              "      <td>0.044028</td>\n",
              "      <td>0.020685</td>\n",
              "      <td>0.031548</td>\n",
              "      <td>0.018656</td>\n",
              "      <td>-0.014099</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.032539</td>\n",
              "      <td>0.015669</td>\n",
              "      <td>-0.010732</td>\n",
              "      <td>0.008629</td>\n",
              "      <td>-0.021994</td>\n",
              "      <td>0.038945</td>\n",
              "      <td>-0.018601</td>\n",
              "      <td>0.045356</td>\n",
              "      <td>-0.026064</td>\n",
              "      <td>0.011444</td>\n",
              "      <td>0.036105</td>\n",
              "      <td>-0.007412</td>\n",
              "      <td>-0.048222</td>\n",
              "      <td>-0.003049</td>\n",
              "      <td>0.006977</td>\n",
              "      <td>-0.029644</td>\n",
              "      <td>-0.048091</td>\n",
              "      <td>0.031447</td>\n",
              "      <td>-0.011046</td>\n",
              "      <td>0.021332</td>\n",
              "      <td>0.006338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gene         0         1         2  ...       996       997       998       999\n",
              "0   197  0.036639  0.092944  0.017719  ...  0.059195 -0.005199  0.018271  0.061782\n",
              "1   198 -0.025610  0.050843  0.016639  ...  0.035979 -0.014246  0.025826  0.019763\n",
              "2   115  0.000612  0.046969  0.002236  ...  0.045566 -0.019954  0.023893  0.015411\n",
              "3    79  0.001370  0.048009  0.038906  ...  0.038563  0.014004 -0.007221  0.042276\n",
              "4   147  0.021828  0.017569 -0.008736  ...  0.031447 -0.011046  0.021332  0.006338\n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwBNqgmo-K6C"
      },
      "source": [
        "# try basic clustering\n",
        "#kMeans_clustering(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNiDwpJRpy2Z"
      },
      "source": [
        "### **(7) Save Dense Matrix to File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_biCN_RpwPr"
      },
      "source": [
        "mlp_df.to_csv(\"ctrl_dense_shortp300100040.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}